{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import warnings\n",
    "import cv2\n",
    "import pickle\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyautogui as pg\n",
    "\n",
    "from time import time, sleep\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from threading import Thread\n",
    "from matplotlib import pyplot as plt\n",
    "from line_profiler import LineProfiler\n",
    "\n",
    "\n",
    "class Samples_container:\n",
    "    imgs_real_part = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/part/*.jpg\")\n",
    "    imgs_color_black = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/color/black/*.jpg\")\n",
    "    imgs_color_white = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/color/white/*.jpg\")\n",
    "    imgs_color_green = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/color/green/*.jpg\")\n",
    "    imgs_color_red = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/color/red/*.jpg\")\n",
    "    imgs_entire = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/entire/*.jpg\")\n",
    "    imgs_part = glob(\"C:/Users/Haya/OneDrive/DevlopingProjects/RoboCup_Cam/Assets/real/part/*.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial settings\n",
    "\n",
    "print(\"OpenCV\", cv2.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"pandas\", pd.__version__)\n",
    "print(\"Pyautogui\", pg.__version__)\n",
    "print(\"Scikit-learn\", sklearn.__version__)\n",
    "\n",
    "warnings.simplefilter('ignore')  # すべての警告を非表示にする\n",
    "\n",
    "\n",
    "def SaveInstances(instance, path):\n",
    "    '''\n",
    "    PickleモジュールのWrapper\n",
    "    instanceのオブジェクトをpathで指定したファイルパスに保存する。\n",
    "    '''\n",
    "    with open(path, mode='wb') as file:\n",
    "        pickle.dump(instance, file, protocol=2)\n",
    "\n",
    "\n",
    "def LoadInstances(path):\n",
    "    '''\n",
    "    PickleモジュールのWrapper\n",
    "    pathに保存されているpickle形式のファイルをオブジェクトとして読み込む。\n",
    "    '''\n",
    "    with open(path, 'rb') as ins:\n",
    "        return pickle.load(ins)\n",
    "\n",
    "\n",
    "samples = Samples_container()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare samples of color\n",
    "\n",
    "def prepare_bgr(paths, code):\n",
    "    temp = np.reshape([[[[\n",
    "        [pixel for pixel in line]\n",
    "        for line in frame]\n",
    "        for frame in cv2.resize(cv2.imread(path), (640, 360))]\n",
    "    ]for path in paths\n",
    "    ], newshape=(-1, 3)\n",
    "    ).astype(np.int64)\n",
    "    temp_code = np.ones(len(temp)) * code\n",
    "    return np.insert(temp, 3, temp_code, axis=1)\n",
    "\n",
    "\n",
    "color_white = prepare_bgr(samples.imgs_color_white, 0)\n",
    "color_black = prepare_bgr(samples.imgs_color_black, 1)\n",
    "color_green = prepare_bgr(samples.imgs_color_green, 2)\n",
    "color_red = prepare_bgr(samples.imgs_color_red, 3)\n",
    "\n",
    "color_all = np.concatenate([color_black, color_green, color_white, color_red, ])\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    np.append(\"{:,}\".format(len(color_black)), np.average(color_black[:2], axis=0).astype(np.int32)),\n",
    "    np.append(\"{:,}\".format(len(color_green)), np.average(color_green[:2], axis=0).astype(np.int32)),\n",
    "    np.append(\"{:,}\".format(len(color_white)), np.average(color_white[:2], axis=0).astype(np.int32)),\n",
    "    np.append(\"{:,}\".format(len(color_red)), np.average(color_red[:2], axis=0).astype(np.int32)),\n",
    "], index=[\"Black\", \"Green\", \"White\", \"Red\"], columns=[\"Samples\", \"Ave. B\", \"Ave. G\", \"Ave. R\", \"Linked code\"])\n",
    "\n",
    "df = df.sort_values(\"Linked code\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color recognizing model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    color_all[:, :-1],\n",
    "    color_all[:, -1:],\n",
    "    stratify=color_all[:, -1:],  # テストに使うデータを階層化する\n",
    "    test_size=0.1,  # テストに使う割合\n",
    ")\n",
    "\n",
    "col_model = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "y_pred = col_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', linewidth=0.3)\n",
    "ax.set_xlabel(\"Predicted\", fontsize=20)\n",
    "ax.set_ylabel(\"Accrual\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color recognizing model test\n",
    "\"\"\" 注意\n",
    "https://teratail.com/questions/114307\n",
    "\n",
    "OpenCVはBGR順、matplotlibはRGB順を前提として扱います。\n",
    "cv2.cvtColor(img, cv2.COLOR_BGR2RGB)にてRGB順に並べ替えることでmatplotlibでも正しい色で表示できるようになります。\n",
    "\"\"\"\n",
    "print(\"Color recognize model >> \", col_model)\n",
    "for path in [samples.imgs_real_part[14], samples.imgs_real_part[17], samples.imgs_real_part[18]]:\n",
    "    # カラーパレットを用意する\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    colors = [\"black\", \"green\", \"white\", \"red\"]\n",
    "    cmap = ListedColormap(colors, name=\"custom\")\n",
    "\n",
    "    # 写真を読み込む\n",
    "    entire_img = cv2.imread(path)\n",
    "    entire_img = cv2.resize(entire_img, (64, 36))\n",
    "    entire_height, entire_width = entire_img.shape[:2]\n",
    "\n",
    "    # 色を識別する\n",
    "    timer_begin = time()\n",
    "    entire_img_result = [col_model.predict(row) for row in reversed(entire_img)]\n",
    "    print(np.array(entire_img_result) * np.reshape(np.arange(0, len(entire_img_result), 1), (-1, 1)))\n",
    "    print(\"Timer: {:,.5f}sec\\nFrame: {:,}px {:,}px\".format(time() - timer_begin, entire_height, entire_width))\n",
    "\n",
    "    # 表示用に調整する\n",
    "    entire_img_result[0][0] = df.loc[\"black\", \"Linked code\"]  # black\n",
    "    entire_img_result[0][1] = df.loc[\"green\", \"Linked code\"]  # green\n",
    "    entire_img_result[0][2] = df.loc[\"white\", \"Linked code\"]  # white\n",
    "    entire_img_result[0][3] = df.loc[\"red\", \"Linked code\"]  # red\n",
    "\n",
    "    # 表示\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(cv2.cvtColor(entire_img, cv2.COLOR_BGR2RGB))  # -> 注意\n",
    "    plt.subplot(122)\n",
    "    plt.pcolormesh(entire_img_result, cmap=cmap)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
